{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CovidStats from JH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elammertsma/COVID-19/blob/master/CovidStats_from_JH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKppfJWLKxVb"
      },
      "source": [
        "First, let's install the required libraries, like FuzzyWuzzy, since a few that we need are not included in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSoDhl5HKyGd"
      },
      "source": [
        "# Prevents all the installation output from cluttering Colab\n",
        "%%capture\n",
        "\n",
        "!pip install fuzzywuzzy\n",
        "!pip install python-Levenshtein\n",
        "!pip install census\n",
        "!pip install countryinfo"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR5U_g0g1hA-"
      },
      "source": [
        "# Project outline\n",
        "\n",
        "## Intended use\n",
        "This project is meant to run as a webhook on GCP Cloud Functions for a Dialogflow integration, but for development purposes I also wanted it to run as a Colab or locally.\n",
        "\n",
        "To do this, we need to run a few checks and execute/install things depending on the environment.\n",
        "\n",
        "We first check if this code is running in Colab or otherwise (e.g. a Google Cloud Function or locally) and we ask for a location. When it's running as a webhook, the webhook function is called directly, including a JSON-formatted location, skipping the \"main\" function. When it's running in Colab or locally, we execute the main funtion to correctly format the requested location in a way that is compatible with the webhook method, artificially creating a JSON request from the query.\n",
        "\n",
        "## Getting the location\n",
        "Once we have the JSON request with a location, we determine what the location means by running it by the Google Maps API, which is very robust and can generally generate an address for even the most malformed and unintuitive location requests.\n",
        "\n",
        "## Getting the Covid statistics\n",
        "With an accurate location in hand, we determine which data to retrieve from Johns Hopkins CSSE on Github, since there are options for US States or US counties and international data. This is updated daily, so we always have recent data to work with. We filter out unneeded data and, since the data includes latitudes and longitudes, we find the distance from the requested location and sort the data by that distance. Sometimes, the JH locations don't match up with Google's locations, so we then check that the address components match, so we're getting the most relevant location instead of just the nearest location. We now have the most relevant data!\n",
        "\n",
        "## Returning results\n",
        "With the best data now defined, we simply format the output as desired. Since I use this to power an action for the Google Assistant, this means returning the data to Dialogflow so that the Google Assistant knows how to use it, but for other API calls and running the code directly, we output data in a more readable format.\n",
        "\n",
        "---\n",
        "\n",
        "## Dev note!\n",
        "**To run this, you will need API keys for the Google Maps API and the US Census API.**\n",
        "\n",
        "The code expects these to be environment variables. The Colab version creates the environment variables from a text file named \"CovidStats_Keys.txt\", which it expects to exist in your \"Colab Notebooks\" folder on Drive (for which you will have to attach your drive to this Colab by running the additional code bock at the bottom of this notebook).\n",
        "\n",
        "CovidStats_Keys.txt and/or the environment variables should be named and formatted as:\n",
        "\n",
        "\n",
        "```\n",
        "GOOGLE_MAPS_KEY:xxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
        "US_CENSUS_KEY:xxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLyMlx7K1f90"
      },
      "source": [
        "# First, check if this is running in Colab\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "  print('Running in Colab!')\n",
        "  get_ipython().system('pip install fuzzywuzzy')\n",
        "  get_ipython().system('pip install python-Levenshtein')\n",
        "  get_ipython().system('pip install census')\n",
        "  get_ipython().system('pip install countryinfo')\n",
        "  get_ipython().system('clear')\n",
        "\n",
        "import os\n",
        "import logging\n",
        "from flask import Flask, request, make_response, jsonify, escape\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import re\n",
        "from geopy.geocoders import GoogleV3\n",
        "from math import pi,sqrt,sin,cos,atan2\n",
        "from fuzzywuzzy import fuzz\n",
        "from census import Census\n",
        "from countryinfo import CountryInfo\n",
        "\n",
        " \n",
        "def fixData(df,country):\n",
        "  orig_size = df.size\n",
        "\n",
        "  # Delete entries that have no location data or are missing confirmed or active cases. (For the latter, we could tell the user there is no data for that location. Instead, we opt to return data on the nearest location with data.)\n",
        "  df.drop(df[pd.isnull(df.Lat) | pd.isnull(df.Long_) | pd.isnull(df.Confirmed) | pd.isnull(df.Active)].index, inplace=True, errors='ignore')\n",
        "\n",
        "  # Exceptions due to differences in country notation between the JH data and Google. These all make comparisons easier later.\n",
        "  if country == 'United States':\n",
        "    df[['Country_Region']] = df[['Country_Region']].replace('^US$', 'United States', regex=True)\n",
        "  if country == 'Côte d\\'Ivoire':\n",
        "    df[['Country_Region']] = df[['Country_Region']].replace('^Cote d\\'Ivoire$', 'Côte d\\'Ivoire', regex=True)\n",
        "  if country == 'Democratic Republic of the Congo':\n",
        "    df[['Country_Region']] = df[['Country_Region']].replace('^Congo \\(Kinshasa\\)$', 'Democratic Republic of the Congo', regex=True)\n",
        "  if country == 'Republic of the Congo':\n",
        "    df[['Country_Region']] = df[['Country_Region']].replace('^Congo \\(Brazzaville\\)$', 'Republic of the Congo', regex=True)\n",
        "  if country == 'South Korea':\n",
        "    df[['Country_Region']] = df[['Country_Region']].replace('^\"Korea, South\"$', 'South Korea', regex=True)\n",
        "\n",
        "  logging.debug('Removing anything that isn\\'t ' + country)\n",
        "  logging.debug(df[df.Country_Region == country].head(3))\n",
        "\n",
        "  # To prevent border-towns from returning data from another country, limit results to the country in which the requested location lies.\n",
        "  df.drop(df[df.Country_Region != country].index, inplace=True, errors='ignore')\n",
        "\n",
        "  df[['Province_State']] = df[['Province_State']].replace(np.nan, '', regex=True) # some countries have territories as states with an empty state entry as the actual country. ugh.\n",
        "  df[['Recovered']] = df[['Recovered']].replace(np.nan, 0, regex=True) # states have empty recovered numbers instead of zero, contrary to countries and counties. ugh.\n",
        "\n",
        "  logging.debug('Removed ' + str(orig_size - df.size) + ' unusable locations from the data. (' + str(100 - df.size/orig_size * 100) + '%)')\n",
        "  return df\n",
        "\n",
        "def haversine(row, location):\n",
        "  \"\"\"This function finds the distance between the\n",
        "  queried location and each row in the data set.\"\"\"\n",
        "\n",
        "  lat1 = row['Lat']\n",
        "  long1 = row['Long_']\n",
        "  lat2 = location['lat']\n",
        "  long2 = location['long']\n",
        "\n",
        "  degree_to_rad = float(pi / 180.0)\n",
        "\n",
        "  d_lat = (lat2 - lat1) * degree_to_rad\n",
        "  d_long = (long2 - long1) * degree_to_rad\n",
        "\n",
        "  a = pow(sin(d_lat / 2), 2) + cos(lat1 * degree_to_rad) * cos(lat2 * degree_to_rad) * pow(sin(d_long / 2), 2)\n",
        "  c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "  km = 6367 * c\n",
        "    \n",
        "  return km\n",
        "\n",
        "def fuzzymatch(row, location):\n",
        "  # This would be neater as a dictionary or tuple, but these\n",
        "  # explicit variables make the code much more readable.\n",
        "  Admin2 = str(row[['Admin2']][0])\n",
        "  Province = str(row[['Province_State']][0])\n",
        "  Country = str(row[['Country_Region']][0])\n",
        "  l_Admin2 = location['l_Admin2']\n",
        "  l_Province = location['l_Province']\n",
        "  l_Country = location['l_Country']\n",
        "\n",
        "  if Admin2 == 'nan':\n",
        "    Admin2 == ''\n",
        "  if Province == 'nan':\n",
        "    Province = ''\n",
        "  if Country == 'nan':\n",
        "    Contry = ''\n",
        "\n",
        "  if Admin2:\n",
        "    admin2_match = fuzz.ratio(Admin2.lower(),l_Admin2.lower())\n",
        "  else:\n",
        "    admin2_match = 0\n",
        "  if Province:\n",
        "    province_match = fuzz.ratio(Province.lower(),l_Province.lower())\n",
        "  else:\n",
        "    province_match = 0\n",
        "  if Country:\n",
        "    country_match = fuzz.ratio(Country.lower(),l_Country.lower())\n",
        "  else:\n",
        "    country_match = 0\n",
        "\n",
        "  logging.debug('Comparing ' + Admin2.lower() + ' with ' + l_Admin2.lower() + ': ' + str(admin2_match))\n",
        "  logging.debug('Comparing ' + Province.lower() + ' with ' + l_Province.lower() + ': ' + str(province_match))\n",
        "  logging.debug('Comparing ' + Country.lower() + ' with ' + l_Country.lower() + ': ' + str(country_match))\n",
        "\n",
        "  # Choose how closely results should match.Too low and it will\n",
        "  # match things that shouldn't match and too high means slight \n",
        "  # variations won't match, like New York City to New York. 70 \n",
        "  # seems to work well.\n",
        "  match_threshhold = 70\n",
        "\n",
        "  if admin2_match > match_threshhold:\n",
        "    return 3\n",
        "  elif province_match > match_threshhold:\n",
        "    return 2\n",
        "  elif country_match > match_threshhold:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def addcounty(row):\n",
        "  if str(row[['Admin2']][0])[-7:].lower() == ' county':\n",
        "    return str(row[['Admin2']][0])\n",
        "  else:\n",
        "    return str(row[['Admin2']][0]) + ' County'\n",
        "\n",
        "def roundbig(number, retain = 3):\n",
        "  l = len(str(number))\n",
        "  r = int(round(number / 10 ** (l - retain)) * 10 ** (l - retain))\n",
        "  number_with_commas = \"{:,}\".format(r)\n",
        "  return number_with_commas\n",
        "\n",
        "def getpopulation(fips):\n",
        "  c = Census(os.getenv('US_CENSUS_KEY'))\n",
        "  logging.debug('Getting population for FIPS ' + str(fips))\n",
        "  if fips > 999:\n",
        "    fips = f'{fips:05}' # pad with zeroes, since the census API needs them\n",
        "    \n",
        "    state_fips = fips[:-3]\n",
        "    county_fips = fips[-3:]\n",
        "    # 'B01003_001E' is the US census field for population\n",
        "    census_info = c.acs5.get(('NAME', 'B01003_001E'), {'for': 'county:' + county_fips, 'in': 'state:' + state_fips})\n",
        "  else:\n",
        "    fips = f'{fips:02}' # pad with zeroes, since the census API needs them\n",
        "    census_info = c.acs5.get(('NAME', 'B01003_001E'), {'for': 'state:' + fips})\n",
        "  logging.debug('census_info: ' + str(census_info))\n",
        "\n",
        "  try:\n",
        "    pop = int(census_info[0]['B01003_001E'])\n",
        "  except:\n",
        "    pop = 0\n",
        "\n",
        "  logging.debug('Population is ' + str(pop))\n",
        "  return pop\n",
        "\n",
        "def getlocation(query):\n",
        "  # query components are {'admin-area', 'business-name', 'city', 'country', 'island', 'shortcut', 'street-address', 'subadmin-area', 'zip-code'}\n",
        "\n",
        "  \n",
        "  # Get the full location from an incomplete query via Google Maps\n",
        "  g = GoogleV3(api_key=os.getenv('GOOGLE_MAPS_KEY'))\n",
        "  # l = g.geocode('Houston St',components={\"administrative_area\": \"CA\"}) # shows limiting bounds by component\n",
        "\n",
        "  l = g.geocode(query)\n",
        "  l_Locality = ''\n",
        "  l_Admin2 = ''\n",
        "  l_Province = ''\n",
        "  l_Country = ''\n",
        "  county = False\n",
        "\n",
        "  logging.info(l.address)\n",
        "\n",
        "  for i in l.raw['address_components']:\n",
        "    if i['types'][0] == 'locality':\n",
        "      l_Locality = i['long_name']\n",
        "    elif i['types'][0] == 'administrative_area_level_2':\n",
        "      l_Admin2 = i['long_name']\n",
        "      if l_Admin2[-7:] == ' County':\n",
        "        l_Admin2 = l_Admin2.replace(' County', '')\n",
        "        county = True\n",
        "    elif i['types'][0] == 'administrative_area_level_1':\n",
        "      l_Province = i['long_name']\n",
        "    elif i['types'][0] == 'country':\n",
        "      l_Country = i['long_name']\n",
        "  if l_Admin2 == '':\n",
        "    l_Admin2 = l_Locality\n",
        "\n",
        "  location = {'l_Locality': l_Locality, 'l_Admin2': l_Admin2, 'l_Province': l_Province, 'l_Country': l_Country, 'lat': l.latitude, 'long': l.longitude, 'county': county}\n",
        "\n",
        "  return location\n",
        "\n",
        "def getstats(location):\n",
        "\n",
        "  # Here, we download latest report from Johns Hopkins git.\n",
        "  # Which report we download depends on the location requested.\n",
        "  # \n",
        "  # There are three files:\n",
        "  # 1. A file with only US states (and territories)\n",
        "  # 2. A file with all countries, for some countries also\n",
        "  #    states and/or territories and (inexplicably) all US\n",
        "  #    counties.\n",
        "  # 3. A few files with timelines of daily cases, deaths and \n",
        "  #    recoveries for the same locales as 1 and 2. We won't be\n",
        "  #    using these for now.\n",
        "  #\n",
        "  # None of the files contain an entry for the US, so we use\n",
        "  # the state data and total it if the user requests the US.\n",
        "\n",
        "  if location['l_Country'] == 'United States' and not (location['l_Locality'] or location['l_Admin2']):\n",
        "    # Download US state data, since the request is for a US state or the US.\n",
        "    logging.debug('US or US state requested')\n",
        "    US = True\n",
        "    report_dir = '/csse_covid_19_daily_reports_us'\n",
        "  else:\n",
        "    # Download US county and international data (which is inexplicably in one file)\n",
        "    logging.debug('US county or international location requested')\n",
        "    US = False\n",
        "    report_dir = '/csse_covid_19_daily_reports'\n",
        "\n",
        "  file_list_url = 'https://api.github.com/repos/CSSEGISandData/COVID-19/contents/csse_covid_19_data' + report_dir\n",
        "  git_raw_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data'\n",
        "  git_raw_url = git_raw_url + report_dir\n",
        "\n",
        "  github_request = requests.get(file_list_url)\n",
        "  if not github_request:\n",
        "    logging.error('Error: Could not get folder content from Github.')\n",
        "    # Raise an error if we can't get data, since we're done.\n",
        "    # \n",
        "    # TODO: Handle this better so the user knows what happened.\n",
        "    # Now, the app will time out and say \"It took too long...\"\n",
        "    gitub_request.raise_for_status()\n",
        "\n",
        "  file_list = github_request.json()\n",
        "  print(file_list)\n",
        "\n",
        "  # Get the name of the last csv in the directory (with a name\n",
        "  # like 31-03-2020.csv). We simply sort this by YYYYMMDD and zero\n",
        "  # any other file names so that the last item is the latest date.\n",
        "  file_list.sort(key = lambda x: x['name'][6:10]+x['name'][0:2]+x['name'][3:5] if (len(x['name']) > 10 and x['name'][6:8] == '20') else '0')\n",
        "  last_report_name = file_list[-1]['name']\n",
        "\n",
        "  logging.info('Getting data from ' + git_raw_url + '/' + last_report_name)\n",
        "  last_report = pd.read_csv(git_raw_url + '/' + last_report_name) # returns a dataframe built from the giant CSV of COVID-19 stats\n",
        "  logging.debug(last_report.head(3))\n",
        "\n",
        "  # Fix data that causes problems.\n",
        "  last_report = fixData(last_report, location['l_Country'])\n",
        "  if last_report.empty:\n",
        "    return False\n",
        "\n",
        "  if not US:\n",
        "\n",
        "    # The user is simply not looking for the US or a US state.\n",
        "\n",
        "    # NOTE! They might still be looking for a location in the US and\n",
        "    # therefore recieve A US COUNTY.\n",
        "\n",
        "    if location['l_Province'] or location['l_Admin2'] or location['l_Locality']:\n",
        "      # A state/province or more detailed location is present in the request,\n",
        "      # meaning we will try to find something more specific.\n",
        "\n",
        "      # Sort locations based on distance from the query result.\n",
        "      last_report['Distance'] = last_report.apply(haversine, args=(location,), axis=1)\n",
        "      last_report = last_report.sort_values('Distance')\n",
        "      nearest = last_report[['FIPS','Admin2','Province_State','Country_Region','Distance','Confirmed','Deaths','Recovered','Active']].head(5)\n",
        "\n",
        "      # Of the nearest locations with data, find the one that most closely \n",
        "      # resembles the address the user was looking for. This isn't always the \n",
        "      # nearest option. For example, Paris is closer to the center of Belgium \n",
        "      # than the center of France, so asking for Paris would give an illogical \n",
        "      # result if the nearest info was returned.\n",
        "\n",
        "      nearest['Match'] = nearest.apply(fuzzymatch, args=(location,), axis=1)\n",
        "\n",
        "      # The data doesn't include \"county\" at the end of county names, so add it.\n",
        "      if location['county']:\n",
        "        nearest['Admin2'] = nearest.apply(addcounty, axis=1)\n",
        "      sorted_df = nearest.sort_values('Match', ascending=False)\n",
        "\n",
        "      bestmatch_specificity = int(sorted_df[['Match']].iloc[0])\n",
        "      bestmatch_name = str(sorted_df.iloc[0,4-bestmatch_specificity]) # returns the county/city, state or country, depending on what matched\n",
        "      if bestmatch_specificity == 1:\n",
        "        # The best match is a country afterall, despite the user wanting a more specific location\n",
        "        is_country = True\n",
        "      else:\n",
        "        is_country = False\n",
        "    else:\n",
        "      is_country = True\n",
        "\n",
        "      # Here, we know the user is looking for a non-US country, so we get\n",
        "      # all entries for that non-US country. Some countries have a single\n",
        "      # entry, but some are split into states/provinces and some have both\n",
        "      # their own entry and entries for territories (which are entered in\n",
        "      # the state/province field, to make it more confusing). Entries\n",
        "      # specific to a country have a blank state/province, so we look for\n",
        "      # this first. If that exists, we can use that and ignore the rest,\n",
        "      # since those appear to always be territories. If a blank entry does\n",
        "      # not exist, the country is split into states/provinces, so we total\n",
        "      # those entries to get the values for the country.\n",
        "\n",
        "      #sorted_df = last_report.loc[last_report['Country_Region'] == location['l_Country']]\n",
        "      sorted_df = last_report.sort_values('Province_State', ascending=True)\n",
        "      if sorted_df[['Province_State']].iloc[0][0]:\n",
        "        # The top entry has a province, so the country doesn't have its own\n",
        "        # entry. Therefore we have to add all provinces together.\n",
        "        totalsseries = sorted_df.sum(numeric_only=True) # creates a vertical series of totals\n",
        "        totalsdf = pd.DataFrame(totalsseries).transpose() # transpose to create a row and make it into a new dataframe\n",
        "        sorted_df = pd.concat([totalsdf, sorted_df], ignore_index = True) # insert the totals at the top, so they get used\n",
        "\n",
        "        bestmatch_specificity = 3\n",
        "        bestmatch_name = location['l_Country']\n",
        "      else:\n",
        "        # the top entry has no province meaning it's the main entry for the\n",
        "        # country, so we're done. (The other entries are usually territories,\n",
        "        # like Curacao which lists Netherlands as the Country.)\n",
        "        bestmatch_specificity = 3\n",
        "        bestmatch_name = sorted_df[['Country_Region']].iloc[0][0]\n",
        "  elif location['l_Province']:\n",
        "    # we're looking for a state\n",
        "    sorted_df = last_report.loc[last_report['Province_State'] == location['l_Province']]\n",
        "    is_country = False\n",
        "\n",
        "    bestmatch_specificity = 3\n",
        "    bestmatch_name = sorted_df[['Province_State']].iloc[0][0]\n",
        "  else:\n",
        "    # we need to add up data for the US\n",
        "    totals_series = last_report.sum(numeric_only=True) # creates a vertical series of totals\n",
        "    totals_df = pd.DataFrame(totals_series).transpose() # transpose to create a row and make it into a new dataframe\n",
        "    sorted_df = pd.concat([totals_df, last_report], ignore_index = True) # insert the totals at the top, so they get used\n",
        "    is_country = True\n",
        "\n",
        "    bestmatch_specificity = 3\n",
        "    bestmatch_name = 'the United States'\n",
        "\n",
        "  logging.debug(sorted_df.head(3))\n",
        "  logging.debug('Location is a country? ' + str(is_country))\n",
        "  logging.debug('Best matching location name: ' + bestmatch_name)\n",
        "  logging.debug('Match level 1 - 3: ' + str(bestmatch_specificity))\n",
        "\n",
        "  if not is_country and location['l_Country'] == 'United States':\n",
        "    logging.debug('Getting population for ' + str(sorted_df[['FIPS']].iloc[0]))\n",
        "    if bestmatch_name == 'New York City':\n",
        "      # The FIPS for NYC is incorrect as it's for Manhattan, while the\n",
        "      # infection counts are for all buros of NY. This would give a much\n",
        "      # lower population of 1.6M, while it should be over 8M, making the\n",
        "      # infection rate seem much worse than it is.\n",
        "      pop = 8336817\n",
        "    else:\n",
        "      # Use the US Census API to get populations of US areas based on FIPS#.\n",
        "      pop = getpopulation(int(sorted_df[['FIPS']].iloc[0]))\n",
        "    if pop:\n",
        "      per = int(pop / int(sorted_df[['Active']].iloc[0]))\n",
        "    else:\n",
        "      per = 0\n",
        "  elif is_country:\n",
        "    # Use the CountryInfo library to get country populations.\n",
        "    pop = CountryInfo(location['l_Country']).population()\n",
        "    if pop:\n",
        "      per = int(pop / int(sorted_df[['Active']].iloc[0]))\n",
        "    else:\n",
        "      per = 0\n",
        "  else:\n",
        "    # We don't know the populations of states/provinces/territories outside\n",
        "    # the US, so return 0.\n",
        "    pop = 0\n",
        "    per = 0\n",
        "  logging.debug('population = ' + str(pop))\n",
        "  \n",
        "  stats = {\n",
        "      'name': bestmatch_name, \n",
        "      'exact_match': bestmatch_specificity, \n",
        "      'confirmed': int(sorted_df[['Confirmed']].iloc[0]), \n",
        "      'recovered': int(sorted_df[['Recovered']].iloc[0]), \n",
        "      'deaths': int(sorted_df[['Deaths']].iloc[0]), \n",
        "      'active': int(sorted_df[['Active']].iloc[0]),\n",
        "      'one_in_every': per,\n",
        "      'population': pop\n",
        "      }\n",
        "\n",
        "  if (stats['exact_match'] < 3 and (location['l_Admin2'] or location['l_Locality'])) or (location['l_Locality'] and location['l_Locality'] != location['l_Admin2']):\n",
        "    stats['exact_match'] = False\n",
        "  else:\n",
        "    stats['exact_match'] = True\n",
        "\n",
        "  return stats\n",
        "\n",
        "def webhook(req):\n",
        "  # GC Functions uses Flask and calls this function with a Flask request\n",
        "  logging.info('Request: ' + str(req))\n",
        "\n",
        "  request_json = req.get_json(silent=True)\n",
        "  request_args = req.args\n",
        "\n",
        "  if request_json:\n",
        "    req = request_json\n",
        "    logging.debug('using request_json')\n",
        "  elif request_args and 'location' in request_args:\n",
        "    req = request_args\n",
        "    logging.debug('using request_args')\n",
        "    if request_args['location'] == 'DF':\n",
        "      # req = json.loads(df_test)\n",
        "      logging.debug('TODO: run a test DF request')\n",
        "\n",
        "  # Test if the request is from DialogFlow\n",
        "  if 'queryResult' in req:\n",
        "    isDF = True\n",
        "    logging.debug('Request originated from Dialogflow.')\n",
        "  else:\n",
        "    isDF = False\n",
        "    logging.debug('Request was direct.')\n",
        "\n",
        "  ## extract the name of the intent which is detected.\n",
        "  if isDF:\n",
        "    try:\n",
        "      detect_intent = req[\"queryResult\"][\"intent\"][\"displayName\"]\n",
        "    except:\n",
        "      detect_intent = 'bad_request'\n",
        "  elif 'location' in req:\n",
        "    detect_intent = 'direct'\n",
        "  else:\n",
        "    detect_intent = 'bad_request'\n",
        "\n",
        "  logging.info('Intent Detected: '+ str(detect_intent))\n",
        "\n",
        "  ## This is how we are going to map the the intent with a function to perform that functionality for that intent\n",
        "  if detect_intent == 'Default Welcome Intent':\n",
        "    res = welcome(req)\n",
        "  elif detect_intent == 'Get Coronavirus Statistics':\n",
        "    location = getlocation(req[\"queryResult\"][\"outputContexts\"][0][\"parameters\"][\"location.original\"])\n",
        "  elif detect_intent == 'test':\n",
        "    res = 'Testing success!'\n",
        "  elif detect_intent == 'bad_request':\n",
        "    res = 'The request did not include a location parameter.'\n",
        "  elif detect_intent == 'direct':\n",
        "    location = getlocation(req[\"location\"])\n",
        "  elif detect_intent == 'raw':\n",
        "    location = getlocation(req)\n",
        "  else:\n",
        "    res = 'Unkown intent! ' + str(detect_intent)\n",
        "\n",
        "  if location:\n",
        "    stats = getstats(location)\n",
        "  else:\n",
        "    res = 'I didn\\'t understand that location. You can ask for any location and I will find the nearest data available.'\n",
        "\n",
        "  if 'rawdata' in req:\n",
        "    response = stats\n",
        "  elif stats == False:\n",
        "    response = 'Unfortunately, no location or data was found for your request.'\n",
        "  else:\n",
        "    if not stats['exact_match']:\n",
        "      inaccuracy = 'The nearest location with data available is ' + stats['name'] + '. '\n",
        "    else:\n",
        "      inaccuracy = ''\n",
        "    if stats['one_in_every']:\n",
        "      perpop =  'In ' + stats['name'] + ', 1 in ' + str(roundbig(stats['one_in_every'], 2)) + ' people potentially have the virus. T'\n",
        "    else:\n",
        "      perpop = 'In ' + stats['name'] + ', t'\n",
        "    if stats['recovered'] > 0:\n",
        "      recoveries = str(roundbig(stats['recovered'])) + ' confirmed recoveries and '\n",
        "    else:\n",
        "      recoveries = ''\n",
        "    response = inaccuracy + perpop + 'here are ' + str(roundbig(stats['confirmed'])) + ' confirmed cases, of which ' + str(roundbig(stats['active'])) + ' are active. There have been ' + recoveries + str(roundbig(stats['deaths'])) + ' deaths.'\n",
        "  if isDF:\n",
        "    followup = ' Would you like the coronavirus statistics about another place?'\n",
        "    response = {'fulfillmentText':response + followup}\n",
        "\n",
        "  ## returning the res from the function for which intent is matched.\n",
        "  logging.info(\"Response: \" + str(response))\n",
        "  return str(response)\n",
        "\n",
        "def main():\n",
        "  logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "# Create a file called CovidStats_Keys.txt\n",
        "# Add your Google Maps Key as:\n",
        "# GOOGLE_MAPS_KEY:xxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
        "# and your US Census Key as:\n",
        "# US_CENSUS_KEY:xxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
        "\n",
        "  if IN_COLAB:\n",
        "    google.colab.drive.mount('/content/drive')\n",
        "    keys_file_path = 'drive/My Drive/Colab Notebooks/CovidStats_Keys.txt'\n",
        "  else:\n",
        "    keys_file_path = 'CovidStats_Keys.txt'\n",
        "\n",
        "  keys = []\n",
        "  with open(keys_file_path) as keysfile:\n",
        "    keys = keysfile.readlines()\n",
        "  for key in keys:\n",
        "    key = key.strip()\n",
        "    keypair = key.split(':')\n",
        "    os.environ[keypair[0]] = keypair[1]\n",
        "    logging.info('Successfully added environment variable ' + keypair[0])\n",
        "\n",
        "  query = str(input('Which location would you like data for?\\n'))\n",
        "\n",
        "  app = Flask(__name__)\n",
        "  with app.test_request_context('?location=' + query): # creates test Flask request\n",
        "    webhook(request)\n",
        "\n",
        "if IN_COLAB:\n",
        "  main()\n",
        "else:\n",
        "  # assumes this file is named webhook.py\n",
        "  if __name__ == \"__main__\":\n",
        "      import CovidStats\n",
        "      CovidStats.main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n2QYikZGUXw"
      },
      "source": [
        "## For Colab Only\n",
        "Run this to get access to your Google Drive, where your API keys file should be stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POjMBi5ktrH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c926c59a-a293-4126-b0b5-17afc81c4a4e"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\", force_remount=True)\n",
        "except:\n",
        "  logging.error('This code block should only be run in Colab.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heuoDX1En-Xs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}